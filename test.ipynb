{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage ingénieur NLP - Test Technique\n",
    "Ettore Hidoux, Janvier 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "La démarche de recherche et l'utilisation du code est présentée dans le notebook `lab.ipynb` et le code répondant aux différentes questions est dans le fichier `lab.py`.\n",
    "\n",
    "Notre logiciel permet d’effectuer des recherches et de visualiser les articles de presse sur un territoire donné. Les recherches peuvent être effectuées en saisissant manuellement des mots-clefs dans une barre de recherche ou en sélectionnant un thème.\n",
    "Une des problématiques rencontrée est la présence de doublons dans nos articles.\n",
    "\n",
    "**Note**: Un article de presse peut se retrouver en plusieurs exemplaires dans les résultats de la recherche et conduire à une perception dégradée de la qualité du logiciel pour le client. Ces doublons peuvent avoir plusieurs origines :\n",
    "\n",
    "1. plusieurs éditions d’un même journal (Ouest France - Edition Sud Vendée, Ouest France - Edition Loire Atlantique…) publient le même article, qui se retrouve plusieurs fois dans nos données ;\n",
    "2. un article est publié dans plusieurs journaux partageant un même éditeur (Var Matin, Nice Matin par exemple) ;\n",
    "3. un article est publié, puis édité et nous est donc envoyé deux fois, dans sa version originale puis dans sa version éditée ;\n",
    "4. un article est transmis en plusieurs formats avec le même contenu légèrement modifié (titres différents, certains paragraphes en moins…) ;\n",
    "  \n",
    "**Objectif**: Nous souhaiterions détecter et éliminer ces doublons.\n",
    "L’objectif du test consistera à proposer une démarche d’identification des doublons au sein d’une liste d’articles de presse.\n",
    "Pour simplifier, on considèrera qu’un article est une structure de données (dictionnaire python, objet, …) comportant les champs/attributs suivants :\n",
    "\n",
    "- id : l’identificant l’exemplaire (les doublons du même article possèdent des identifiants différents)\n",
    "- date_de_publication : la date de publication de l’article (exemple '2021-10-29')\n",
    "- titre : le titre de l’article\n",
    "- texte : le contenu (corps) de l’article"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import du code depuis `lab.py`\n",
    "\n",
    "* On importe le fichier `.py` situé dans le même fichier que ce notebook.\n",
    "* On utilise `autoreload` notebook extension pour que les modifications du fichier `lab.py` soient immédiatement disponible sur le notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 0 - Etude du dataset\n",
    "\n",
    "- Ajout d'une ligne pour avoir un triple doublon afin d'être sur que tout est bien supprimé.\n",
    "- On mélange le dataset pour avoir tout les configurations (pas toujours supprimer le deuxième pareil).\n",
    "- Comme on va travailler sur une liste d'ids (c'est l'output souhaité), création d'une fonction pour selectionner des infos du dataset en fonction de l'id et des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titre</th>\n",
       "      <th>texte</th>\n",
       "      <th>date_de_publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a730bc8e1c762d7535314c6e74f7b42</td>\n",
       "      <td>La BEI, la banque européenne qui se chauffe po...</td>\n",
       "      <td>La BEI, la banque européenne qui se chauffe po...</td>\n",
       "      <td>2021-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6d834976cb9f73ef7ad97649d6a6659b</td>\n",
       "      <td>Entre Caumont et Chérienne, l'implantation d'u...</td>\n",
       "      <td>Le Conseil d'État doit rendre sa décision défi...</td>\n",
       "      <td>2021-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35f28a0ba422f5b7d1ccb47a5a1995b5</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales...</td>\n",
       "      <td>2021-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94d3075509c18863da530cf66ee9d8d7</td>\n",
       "      <td>Matour  Des travaux au centre-bourg</td>\n",
       "      <td>Depuis plusieurs semaines, les travaux au cent...</td>\n",
       "      <td>2021-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d124cab43bed3364cd89bb202eb6b813</td>\n",
       "      <td>Quelques 12 septembre</td>\n",
       "      <td>Quelques 12 septembre\\n\\n1494 naissance du roi...</td>\n",
       "      <td>2021-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3cdab92b6507eb01ca1a039e648de497</td>\n",
       "      <td>Entre Caumont et Chérienne, l'implantation d'u...</td>\n",
       "      <td>Le Conseil d'État doit rendre sa décision défi...</td>\n",
       "      <td>2021-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7d85234a6b7055bd78ab39f5176a9577</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales...</td>\n",
       "      <td>2021-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bd4c53f55cca9e4e87cdeb47f44e3d09</td>\n",
       "      <td>Quelques 12 septembre</td>\n",
       "      <td>Quelques 12 septembre\\n\\n1494 naissance du roi...</td>\n",
       "      <td>2021-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acdc416b2c4fa25d6d91d9257408f6dc</td>\n",
       "      <td>Des travaux au centre-bourg</td>\n",
       "      <td>Depuis plusieurs semaines, les travaux au cent...</td>\n",
       "      <td>2021-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>580a7eb5b805adfba3385d648cc0ec53</td>\n",
       "      <td>La BEI, la banque européenne QUI SE CHAUFFE PO...</td>\n",
       "      <td>La BEI, la banque européenne QUI SE CHAUFFE PO...</td>\n",
       "      <td>2021-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7d85234a2c4055bd78ab39f5176a9577</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales...</td>\n",
       "      <td>2021-09-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0   5a730bc8e1c762d7535314c6e74f7b42   \n",
       "1   6d834976cb9f73ef7ad97649d6a6659b   \n",
       "2   35f28a0ba422f5b7d1ccb47a5a1995b5   \n",
       "3   94d3075509c18863da530cf66ee9d8d7   \n",
       "4   d124cab43bed3364cd89bb202eb6b813   \n",
       "5   3cdab92b6507eb01ca1a039e648de497   \n",
       "6   7d85234a6b7055bd78ab39f5176a9577   \n",
       "7   bd4c53f55cca9e4e87cdeb47f44e3d09   \n",
       "8   acdc416b2c4fa25d6d91d9257408f6dc   \n",
       "9   580a7eb5b805adfba3385d648cc0ec53   \n",
       "10  7d85234a2c4055bd78ab39f5176a9577   \n",
       "\n",
       "                                                titre  \\\n",
       "0   La BEI, la banque européenne qui se chauffe po...   \n",
       "1   Entre Caumont et Chérienne, l'implantation d'u...   \n",
       "2      La littérature vaine aux Bibliothèques Idéales   \n",
       "3                 Matour  Des travaux au centre-bourg   \n",
       "4                               Quelques 12 septembre   \n",
       "5   Entre Caumont et Chérienne, l'implantation d'u...   \n",
       "6      La littérature vaine aux Bibliothèques Idéales   \n",
       "7                               Quelques 12 septembre   \n",
       "8                         Des travaux au centre-bourg   \n",
       "9   La BEI, la banque européenne QUI SE CHAUFFE PO...   \n",
       "10     La littérature vaine aux Bibliothèques Idéales   \n",
       "\n",
       "                                                texte date_de_publication  \n",
       "0   La BEI, la banque européenne qui se chauffe po...          2021-11-01  \n",
       "1   Le Conseil d'État doit rendre sa décision défi...          2021-09-26  \n",
       "2   La littérature vaine aux Bibliothèques Idéales...          2021-09-11  \n",
       "3   Depuis plusieurs semaines, les travaux au cent...          2021-09-27  \n",
       "4   Quelques 12 septembre\\n\\n1494 naissance du roi...          2021-09-11  \n",
       "5   Le Conseil d'État doit rendre sa décision défi...          2021-09-26  \n",
       "6   La littérature vaine aux Bibliothèques Idéales...          2021-09-11  \n",
       "7   Quelques 12 septembre\\n\\n1494 naissance du roi...          2021-09-12  \n",
       "8   Depuis plusieurs semaines, les travaux au cent...          2021-09-27  \n",
       "9   La BEI, la banque européenne QUI SE CHAUFFE PO...          2021-11-01  \n",
       "10  La littérature vaine aux Bibliothèques Idéales...          2021-09-12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('./data/input.json')\n",
    "new = df.loc[2, :].copy()\n",
    "new.id = '7d85234a2c4055bd78ab39f5176a9577'\n",
    "new.date_de_publication = '2021-09-12'\n",
    "df = df.append(new).reset_index(inplace=False, drop=True)\n",
    "df.date_de_publication = pd.to_datetime(df.date_de_publication)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     False\n",
       "titre                  False\n",
       "texte                  False\n",
       "date_de_publication    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if text can be totally equal\n",
    "df.loc[2, 'texte'] == df.loc[3, 'texte']\n",
    "# check if row can be equal (title, date and text)\n",
    "df.loc[2, :] == df.loc[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5a730bc8e1c762d7535314c6e74f7b42',\n",
       " '6d834976cb9f73ef7ad97649d6a6659b',\n",
       " '35f28a0ba422f5b7d1ccb47a5a1995b5',\n",
       " '94d3075509c18863da530cf66ee9d8d7',\n",
       " 'd124cab43bed3364cd89bb202eb6b813',\n",
       " '3cdab92b6507eb01ca1a039e648de497',\n",
       " '7d85234a6b7055bd78ab39f5176a9577',\n",
       " 'bd4c53f55cca9e4e87cdeb47f44e3d09',\n",
       " 'acdc416b2c4fa25d6d91d9257408f6dc',\n",
       " '580a7eb5b805adfba3385d648cc0ec53',\n",
       " '7d85234a2c4055bd78ab39f5176a9577']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list with article ids \n",
    "text_ids = list(df.id)\n",
    "text_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales...</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texte  \\\n",
       "0  La littérature vaine aux Bibliothèques Idéales...   \n",
       "\n",
       "                                            titre  \n",
       "0  La littérature vaine aux Bibliothèques Idéales  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to select row of the dataset by id \n",
    "def selectById(id, col=None):\n",
    "    if col == None:\n",
    "        return df.loc[df.id == id, :].reset_index(inplace=False, drop=True)\n",
    "    else:\n",
    "        if type(col)==list:\n",
    "            return df.loc[df.id == id, col].reset_index(inplace=False, drop=True)\n",
    "        else:\n",
    "            return df.loc[df.id == id, col].values[0]\n",
    "    \n",
    "selectById('580a7eb5b805adfba3385d648cc0ec53', 'texte')\n",
    "selectById('7d85234a2c4055bd78ab39f5176a9577', ['texte', 'titre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(selectById('5a730bc8e1c762d7535314c6e74f7b42', ['texte', 'titre']) == selectById('7d85234a2c4055bd78ab39f5176a9577', ['texte', 'titre'])).sum(1).values[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Doublons exacts\n",
    "Proposer un script permettant d'écarter les doublons exacts. \n",
    "\n",
    "Il peut y avoir plus de deux exemplaires d’un même article, votre script doit en tenir compte, c’est-à-dire qu’en sortie, on ne veut qu’un simple exemplaire de l’article qu’il y ait 1 ou 6 doublons.\n",
    "\n",
    "**Explication:**\n",
    "On parcourt la liste d'id d'articles une premiere fois puis une deuxième en excluant ceux déjà parcourut. Si le titre et le text sont exactement les mêmes on retire le second de la liste (simplicité, supprimer le premier demande de sortir de la boucle et ajoute une ligne `break`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35f28a0ba422f5b7d1ccb47a5a1995b5 7d85234a6b7055bd78ab39f5176a9577\n",
      "35f28a0ba422f5b7d1ccb47a5a1995b5 7d85234a2c4055bd78ab39f5176a9577\n",
      "d124cab43bed3364cd89bb202eb6b813 bd4c53f55cca9e4e87cdeb47f44e3d09\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "text_ids = list(df.id)\n",
    "for id1 in text_ids:\n",
    "    #print(id1)\n",
    "    for id2 in text_ids[text_ids.index(id1)+1:]:\n",
    "        #print(' ', id2)\n",
    "        is_equal = (selectById(id1, ['texte', 'titre']) == selectById(id2, ['texte', 'titre']))\n",
    "        if is_equal.sum(1).values[0] == 2:\n",
    "            text_ids.remove(id2)\n",
    "            print(id1, id2)\n",
    "            \n",
    "print(len(text_ids))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5a730bc8e1c762d7535314c6e74f7b42',\n",
       " '6d834976cb9f73ef7ad97649d6a6659b',\n",
       " '35f28a0ba422f5b7d1ccb47a5a1995b5',\n",
       " '94d3075509c18863da530cf66ee9d8d7',\n",
       " 'd124cab43bed3364cd89bb202eb6b813',\n",
       " '3cdab92b6507eb01ca1a039e648de497',\n",
       " 'acdc416b2c4fa25d6d91d9257408f6dc',\n",
       " '580a7eb5b805adfba3385d648cc0ec53']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeExactDuplicates(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Doublons exacts ou presque\n",
    "Généraliser votre script pour écarter les doublons exacts ou presque. La règle de priorité est de :\n",
    "\n",
    "1. garder l’article le plus récent\n",
    "2. si tous les articles similaires sont publiés le même jour, garder le titre le plus court\n",
    "3. si tous les articles ont le même titre, le choix est arbitraire\n",
    "\n",
    "**Explications:**\n",
    "\n",
    "- Premeierement, j'ai créé une function qui, à partir de deux ids, revoient l'id de l'article à suprimer de la liste en respectant les consignes ci-dessus.\n",
    "- Ensuite, j'ai utilisé la librairie `difflib` (très utile pour le versionning) et notamment la classe `SequenceMatcher` pour obtenir les séquence de characteres qui correspondent d'un article à l'autre.\n",
    "- Le score est obtenue par: (2*M)/T, ou M est la somme des taille des séquences matchées et T la somme des tailles des deux articles.\n",
    "- Pour finir, en utilisant la double boucle précédante, si le score est supérieur à 0.9 (valeur arbitraire définie dans notre cas pour que çà marche, une étude avec plus d'article serait souhaitable pour déterminer ce seuil plus précisement), on utilise la première fonction pour savoir quelle article retirer et le retirer.\n",
    "- Dans le cas de ce petit dataset, le temps de calcul du score n'est pas important mais à grande échelle il serait possible d'utiliser `real_quick_ratio` qui est 6x plus rapide.\n",
    "- D'autre librairies existent pour calculer le score de ressemblance, en utilisant d'autres aspect, il est également possible de le faire en etudiant la fréquence d'apparition des mots, ou encore, des n-grams. (le score utilisant la fréquence des mots a été réalisé à la suite mais un peut moins performant en quantité de code mais semble plus rapide, à vérifier sur un plus grand échantillon de données) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def article2Remove(id1, id2):\n",
    "    if df.loc[id1, 'date_de_publication'] == df.loc[id2, 'date_de_publication']:\n",
    "        return int(len(df.loc[id1, 'titre']) >= len(df.loc[id2, 'titre']))\n",
    "    else:\n",
    "        return int(\n",
    "            df.loc[id1, 'date_de_publication'] > df.loc[id2, 'date_de_publication'])\n",
    "       \n",
    "article2Remove(0, 1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "text1 = selectById('5a730bc8e1c762d7535314c6e74f7b42', ['texte']).values[0]\n",
    "text2 = selectById('580a7eb5b805adfba3385d648cc0ec53', ['texte']).values[0]\n",
    "d = difflib.Differ()\n",
    "diffs = [x for x in d.compare(io.StringIO(text1[0]).readlines(), io.StringIO(text2[0]).readlines()) if x[0] in ('+', '-')]\n",
    "print(len(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La BEI, la banque européenne qui se chauffe pour l'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 ms, sys: 219 µs, total: 8.48 ms\n",
      "Wall time: 8.31 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9237445753254805"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "difflib.SequenceMatcher(None, text1[0], text2[0]).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 ms, sys: 3 µs, total: 1.61 ms\n",
      "Wall time: 1.62 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9511779293242405"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "difflib.SequenceMatcher(None, text1[0], text2[0]).quick_ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 629 µs, sys: 2 µs, total: 631 µs\n",
      "Wall time: 632 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9514879107253564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "difflib.SequenceMatcher(None, text1[0], text2[0]).real_quick_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "#nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc1 = nlp(text1)\n",
    "doc2 = nlp(text2)\n",
    "doc3 = nlp(selectById('acdc416b2c4fa25d6d91d9257408f6dc', ['texte']).values[0])\n",
    "\n",
    "print(doc1.similarity(doc2)) \n",
    "print(doc1.similarity(doc3))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a730bc8e1c762d7535314c6e74f7b42 580a7eb5b805adfba3385d648cc0ec53\n",
      "0.9237445753254805\n",
      "580a7eb5b805adfba3385d648cc0ec53\n",
      "35f28a0ba422f5b7d1ccb47a5a1995b5 7d85234a6b7055bd78ab39f5176a9577\n",
      "1.0\n",
      "7d85234a6b7055bd78ab39f5176a9577\n",
      "35f28a0ba422f5b7d1ccb47a5a1995b5 7d85234a2c4055bd78ab39f5176a9577\n",
      "1.0\n",
      "35f28a0ba422f5b7d1ccb47a5a1995b5\n",
      "here\n",
      "94d3075509c18863da530cf66ee9d8d7 acdc416b2c4fa25d6d91d9257408f6dc\n",
      "1.0\n",
      "acdc416b2c4fa25d6d91d9257408f6dc\n",
      "d124cab43bed3364cd89bb202eb6b813 bd4c53f55cca9e4e87cdeb47f44e3d09\n",
      "1.0\n",
      "d124cab43bed3364cd89bb202eb6b813\n",
      "here\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "text_ids, to_remove = list(df.id), []\n",
    "for id1 in text_ids:\n",
    "    for id2 in text_ids[text_ids.index(id1)+1:]:\n",
    "        if (id1 not in to_remove) & (id2 not in to_remove):\n",
    "            #print('         ', id2)\n",
    "            text1 = selectById(id1, ['texte']).values[0]\n",
    "            text2 = selectById(id2, ['texte']).values[0]     \n",
    "            ratio = difflib.SequenceMatcher(None, text1[0], text2[0]).ratio()\n",
    "            if ratio >= 0.9:\n",
    "                print(id1, id2)\n",
    "                print(ratio)\n",
    "                #print(selectById(id1, ['titre', 'date_de_publication']))\n",
    "                #print(selectById(id2, ['titre', 'date_de_publication']))\n",
    "                print(articleToRemove(df, id1, id2))\n",
    "                to_remove.append(articleToRemove(df, id1, id2))\n",
    "                if articleToRemove(df, id1, id2)==id1:\n",
    "                    print('here')\n",
    "                    break\n",
    "for id in to_remove:\n",
    "    text_ids.remove(id)\n",
    "            \n",
    "print(len(text_ids))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 1.25 ms, total: 129 ms\n",
      "Wall time: 128 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['5a730bc8e1c762d7535314c6e74f7b42',\n",
       " '6d834976cb9f73ef7ad97649d6a6659b',\n",
       " '94d3075509c18863da530cf66ee9d8d7',\n",
       " '3cdab92b6507eb01ca1a039e648de497',\n",
       " 'bd4c53f55cca9e4e87cdeb47f44e3d09',\n",
       " '7d85234a2c4055bd78ab39f5176a9577']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "removeDuplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n",
      "425\n",
      "473\n",
      "0.10147991543340384\n"
     ]
    }
   ],
   "source": [
    "# pour obtenir la fréquence des mot\n",
    "from collections import Counter \n",
    "# pour nettoyer le texte et retirer les accents et caractères spéciaux\n",
    "from unidecode import unidecode\n",
    "# pour nettoyer le texte et retirer les stopwords\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "\n",
    "\n",
    "#print(fr_stop)\n",
    "\n",
    "txt1, txt2 = text1[0], text2[0]\n",
    "for p in ['\\n', '\\xa0', '.', ':', ',', '!', '?', ';', '«', '»', '(', ')', '’']:\n",
    "    txt1 = txt1.replace(p, ' ')\n",
    "    txt2 = txt2.replace(p, ' ')\n",
    "    \n",
    "txt1, txt2 = unidecode(txt1.lower()).split(), unidecode(txt2.lower()).split()\n",
    "    \n",
    "for w1, w2 in zip(txt1, txt2):\n",
    "    if w1 in fr_stop:\n",
    "        txt1.remove(w1)\n",
    "    if w2 in fr_stop:\n",
    "        txt2.remove(w2)\n",
    "        \n",
    "freq1, freq2 = Counter(txt1), Counter(txt2)   \n",
    "words = list(freq1.keys())\n",
    "words.extend(list(freq2.keys()))\n",
    "words = list(set(words))\n",
    "\n",
    "print(len(words))\n",
    "\n",
    "diff = []\n",
    "some = []\n",
    "for word in words:\n",
    "    # print(freq1[word], freq2[word])\n",
    "    diff.append(abs(freq1[word]-freq2[word]))\n",
    "    some.append(freq1[word])\n",
    "    some.append(freq2[word])\n",
    "    \n",
    "\n",
    "print(sum(diff))\n",
    "print(sum(some))\n",
    "print(1-(sum(diff)/sum(some)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02863961813842486"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFrequencyScore(text1[0], text2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a730bc8e1c762d7535314c6e74f7b42\n",
      "6d834976cb9f73ef7ad97649d6a6659b\n",
      "35f28a0ba422f5b7d1ccb47a5a1995b5\n",
      "d124cab43bed3364cd89bb202eb6b813\n",
      "bd4c53f55cca9e4e87cdeb47f44e3d09\n",
      "acdc416b2c4fa25d6d91d9257408f6dc\n",
      "7d85234a2c4055bd78ab39f5176a9577\n",
      "['5a730bc8e1c762d7535314c6e74f7b42', '6d834976cb9f73ef7ad97649d6a6659b', '94d3075509c18863da530cf66ee9d8d7', '3cdab92b6507eb01ca1a039e648de497', 'bd4c53f55cca9e4e87cdeb47f44e3d09', 'acdc416b2c4fa25d6d91d9257408f6dc', '7d85234a2c4055bd78ab39f5176a9577']\n",
      "CPU times: user 65.4 ms, sys: 1.52 ms, total: 66.9 ms\n",
      "Wall time: 66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_ids = list(df.id)\n",
    "for id1 in text_ids:\n",
    "    print(id1)\n",
    "    for id2 in text_ids[text_ids.index(id1)+1:]:\n",
    "        text1 = selectArticleById(df, id1, ['texte']).values[0]\n",
    "        text2 = selectArticleById(df, id2, ['texte']).values[0]     \n",
    "        ratio = wordFrequencyScore(text1[0], text2[0])\n",
    "        if ratio >= 0.9:\n",
    "            text_ids.remove(articleToRemove(df, id1, id2))\n",
    "            if articleToRemove(df, id1, id2) == id1:\n",
    "                break\n",
    "            \n",
    "print(text_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe serait le même avec des n-grams, la différence serait apres le split, au lieu de conserver des mots seuls on les assembleraient par groupe de n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Doublons inclusifs\n",
    "Généraliser votre script pour écarter les doublons inclusifs. La règle de priorité est de :\n",
    "- garder l’article le plus long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a730bc8e1c762d7535314c6e74f7b42 580a7eb5b805adfba3385d648cc0ec53\n",
      "0.9237445753254805\n",
      "580a7eb5b805adfba3385d648cc0ec53\n",
      "6d834976cb9f73ef7ad97649d6a6659b 3cdab92b6507eb01ca1a039e648de497\n",
      "0.550180980585719\n",
      "94d3075509c18863da530cf66ee9d8d7 acdc416b2c4fa25d6d91d9257408f6dc\n",
      "1.0\n",
      "acdc416b2c4fa25d6d91d9257408f6dc\n",
      "d124cab43bed3364cd89bb202eb6b813 bd4c53f55cca9e4e87cdeb47f44e3d09\n",
      "1.0\n",
      "d124cab43bed3364cd89bb202eb6b813\n",
      "7d85234a6b7055bd78ab39f5176a9577 7d85234a2c4055bd78ab39f5176a9577\n",
      "1.0\n",
      "7d85234a6b7055bd78ab39f5176a9577\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "text_ids = list(df.id)\n",
    "for id1 in text_ids:\n",
    "    #print(id1)\n",
    "    for id2 in text_ids[text_ids.index(id1)+1:]:\n",
    "        #print(' ', id2)\n",
    "        text1 = selectById(id1, ['texte']).values[0]\n",
    "        text2 = selectById(id2, ['texte']).values[0]     \n",
    "        ratio = difflib.SequenceMatcher(None, text1[0], text2[0]).ratio()\n",
    "        if ratio >= 0.9:\n",
    "            print(id1, id2)\n",
    "            print(ratio)\n",
    "            #print(selectById(id1, ['titre', 'date_de_publication']))\n",
    "            #print(selectById(id2, ['titre', 'date_de_publication']))\n",
    "            print(articleToRemove(df, id1, id2))\n",
    "            text_ids.remove(articleToRemove(df, id1, id2))\n",
    "        elif ratio >= 0.5:\n",
    "            print(id1, id2)\n",
    "            print(ratio)\n",
    "            text1 = len(selectById(id1, ['texte']).values[0])\n",
    "            text2 = len(selectById(id2, ['texte']).values[0])\n",
    "            id = id2\n",
    "            if text1 >= text2:\n",
    "                id = id1\n",
    "            text_ids.remove(id)\n",
    "\n",
    "            \n",
    "print(len(text_ids)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5a730bc8e1c762d7535314c6e74f7b42',\n",
       " '94d3075509c18863da530cf66ee9d8d7',\n",
       " '3cdab92b6507eb01ca1a039e648de497',\n",
       " 'bd4c53f55cca9e4e87cdeb47f44e3d09',\n",
       " '7d85234a2c4055bd78ab39f5176a9577']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeDuplicatesAndInsides(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titre</th>\n",
       "      <th>texte</th>\n",
       "      <th>date_de_publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a730bc8e1c762d7535314c6e74f7b42</td>\n",
       "      <td>La BEI, la banque européenne qui se chauffe po...</td>\n",
       "      <td>La BEI, la banque européenne qui se chauffe po...</td>\n",
       "      <td>2021-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94d3075509c18863da530cf66ee9d8d7</td>\n",
       "      <td>Matour  Des travaux au centre-bourg</td>\n",
       "      <td>Depuis plusieurs semaines, les travaux au cent...</td>\n",
       "      <td>2021-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3cdab92b6507eb01ca1a039e648de497</td>\n",
       "      <td>Entre Caumont et Chérienne, l'implantation d'u...</td>\n",
       "      <td>Le Conseil d'État doit rendre sa décision défi...</td>\n",
       "      <td>2021-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bd4c53f55cca9e4e87cdeb47f44e3d09</td>\n",
       "      <td>Quelques 12 septembre</td>\n",
       "      <td>Quelques 12 septembre\\n\\n1494 naissance du roi...</td>\n",
       "      <td>2021-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7d85234a2c4055bd78ab39f5176a9577</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales</td>\n",
       "      <td>La littérature vaine aux Bibliothèques Idéales...</td>\n",
       "      <td>2021-09-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0   5a730bc8e1c762d7535314c6e74f7b42   \n",
       "3   94d3075509c18863da530cf66ee9d8d7   \n",
       "5   3cdab92b6507eb01ca1a039e648de497   \n",
       "7   bd4c53f55cca9e4e87cdeb47f44e3d09   \n",
       "10  7d85234a2c4055bd78ab39f5176a9577   \n",
       "\n",
       "                                                titre  \\\n",
       "0   La BEI, la banque européenne qui se chauffe po...   \n",
       "3                 Matour  Des travaux au centre-bourg   \n",
       "5   Entre Caumont et Chérienne, l'implantation d'u...   \n",
       "7                               Quelques 12 septembre   \n",
       "10     La littérature vaine aux Bibliothèques Idéales   \n",
       "\n",
       "                                                texte date_de_publication  \n",
       "0   La BEI, la banque européenne qui se chauffe po...          2021-11-01  \n",
       "3   Depuis plusieurs semaines, les travaux au cent...          2021-09-27  \n",
       "5   Le Conseil d'État doit rendre sa décision défi...          2021-09-26  \n",
       "7   Quelques 12 septembre\\n\\n1494 naissance du roi...          2021-09-12  \n",
       "10  La littérature vaine aux Bibliothèques Idéales...          2021-09-12  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.id.isin(removeDuplicatesAndInsides(df)), :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui correspond bien à la liste contenue dans `output.json`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 - ML model \n",
    "Proposer (sans l’implémenter) une approche utilisant le machine learning pour détecter automatiquement les articles similaires. Vous décrirez une stratégie pour constituer un dataset d’entraînement, les features que vous pensez inclure dans votre modèle et la stratégie d'évaluation du modèle. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Rassembler des données \n",
    "\n",
    "Il faut constituer un dataset équivalent au precédent, celui utilisé dans cette exercice.\n",
    "\n",
    "## Part 2 - Transformer ces données\n",
    "\n",
    "Ensuite plusieurs étapes sont nécessaires (entre autre un algorithme de machine learning nécessite des valeurs numériques):\n",
    "\n",
    "1. Créer un nouveau dataset:\n",
    "   - colonne 1: article 1 (seulement le texte ou le titre, retour à la ligne deux fois plus le texte)\n",
    "   - colonne 2: article 2 (seulement le texte ou le titre, retour à la ligne deux fois plus le texte)\n",
    "   - label: ça peut être 1 ou 0 pour doublon ou pas mais aussi 0, 1 ou 2 pour pas doublon, doublon ou inclus\n",
    "<br><br>\n",
    "\n",
    "2. On ne peut pas garder les deux premières colonnes sous forme de texte, on doit donc les transformer:\n",
    "   - features simples: taille, nombre de mots, ...\n",
    "   - features croisées: scores de comparaison des fréquence de mots ou même de n-grams.\n",
    "   - scores de matching: difflib, fuzzywuzzy, pairwise distances with sklearn, ...\n",
    "   - cf https://medium.springboard.com/identifying-duplicate-questions-a-machine-learning-case-study-37117723844 pour les idées de métriques à utiliser \n",
    "\n",
    "## Part 3 - Entrainer un modèle \n",
    "\n",
    "1. Serparer le dataset en deux (coefficient 0.25 à 0.3) pour obtenir un dataset d'entrainement et un de test \n",
    "2. Ensuite, on peut utilisé plusieurs modèles de machine learning de classification offert par scikit learn (regression logistique, decision tree, random forest, ...) cf https://scikit-learn.org/stable/supervised_learning.html#supervised-learning ou encore tensorflow ou pytorch pour faire du deep learning et aller plus loin.\n",
    "3. On entraine le modèle avec le dataset d'entrainement.\n",
    "4. On teste le modèle avec le dataset d'entrainement. \n",
    "\n",
    "## Part 4 - Hypertuning \n",
    "\n",
    "1. Après avoir selection, le ou les modèles les plus performants.\n",
    "2. On peut faire varier les paramètres du modèle pour essayer d'améliorer le score finale (avec un GridSearch par example).\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:16) \n[Clang 12.0.1 ]"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(car_null_hypoth()) <= set(range(1, 7))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> set(car_alt_hypoth()) <= set(range(1, 7))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> set(car_test_stat()) <= set(range(1, 5))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> car_p_value() in set(range(1, 6))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> cleaned.shape[0] == df.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> cleaned['nation'].nunique() == 59\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(info) == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all([isinstance(x, y) for x, y in zip(info, [str, float, int, str])])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (info[1] >= 0) & (info[1] <= 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> universities_out.shape[0] == cleaned.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all(universities_out.columns == ['institution', 'nation', 'score'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.all(abs(universities_out.select_dtypes(include='number').mean()) < 10**-7)  # standard units should average to 0!\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> len(su_and_spread_out) == 2\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> su_and_spread_out[0] in np.arange(1, 4)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(su_and_spread_out[1], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q4_out, pd.DataFrame) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(q4_out) == 5000\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> try:\n...     read_linkedin_survey('nonexistentfile')\n... except FileNotFoundError:\n...     print(True)\nTrue\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(stats_out) == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[0], float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[2], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q5_out, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q5_out.shape == (1000, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> try:\n...     read_student_surveys('nonexistentfile')\n... except FileNotFoundError:\n...     print(True)\nTrue\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> check_credit_out.shape == (1000, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> check_credit_out['ec'].max() == 6\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(out_01, str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(out_02) == len(owners)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'Sarah' in out_02.index\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'Cookie' in out_02.values\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(out_03.index) <= set(owners['City'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "bada3f752f9ffb4a36e22b9957204165790d2a352948163d32c044c30f2f6ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
